# handwriting_recognition_system/core/trainer.py
import json
import os
import time
import torch
from typing import Dict, Any, Callable


class Trainer:
    """
    è´Ÿè´£æ¨¡å‹è®­ç»ƒé€»è¾‘ï¼š
    1. æ¥æ”¶ConfigManager -> ä½¿ç”¨ModelFactoryåˆ›å»ºè®­ç»ƒç»„ä»¶
    2. æ‰§è¡Œè®­ç»ƒä¸éªŒè¯å¾ªç¯
    3. å®æ—¶è¾“å‡ºè®­ç»ƒæ—¥å¿—ï¼Œå¹¶æ”¯æŒå¤–éƒ¨å›è°ƒå‡½æ•°æ¨é€è®­ç»ƒè¿›åº¦
    4. ä¿å­˜è®­ç»ƒå®Œæˆçš„æ¨¡å‹åˆ° storage/trained_models/
    """

    def __init__(self, components, progress_callback: Callable[[Dict[str, Any]], None] = None):
        self.components = components
        self.progress_callback = progress_callback  # ç”¨äºweb_serverå®æ—¶æ¨é€è®­ç»ƒçŠ¶æ€
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.logs = []  # ç”¨äºè®°å½•æ‰€æœ‰epochçš„æ—¥å¿—

    def train(self):
        # === åˆå§‹åŒ–ç»„ä»¶ ===
        model = self.components["model"].to(self.device)
        data_loaders = self.components["data_loaders"]
        optimizer = self.components["optimizer"]
        criterion = self.components["criterion"]
        training_config = self.components["training_config"]

        train_loader = data_loaders["train"]
        val_loader = data_loaders["val"]

        num_epochs = training_config["hyperparameters"].get("epochs", 10)
        model_name = training_config["save_model_name"]
        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        save_dir = os.path.join(os.path.dirname(__file__), '../storage/trained_models')
        os.makedirs(save_dir, exist_ok=True)

        print(f"å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
        print(f"ä¿å­˜è·¯å¾„: {os.path.abspath(save_dir)}")

        # === è®­ç»ƒå¾ªç¯ ===
        for epoch in range(num_epochs):
            model.train()
            running_loss, correct, total = 0.0, 0, 0

            for images, labels in train_loader:
                images, labels = images.to(self.device), labels.to(self.device)

                optimizer.zero_grad()
                outputs = model(images)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                running_loss += loss.item() * images.size(0)
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()

            train_loss = running_loss / total
            train_acc = correct / total

            # === éªŒè¯ ===
            model.eval()
            val_loss, val_correct, val_total = 0.0, 0, 0
            with torch.no_grad():
                for images, labels in val_loader:
                    images, labels = images.to(self.device), labels.to(self.device)
                    outputs = model(images)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item() * images.size(0)
                    _, predicted = outputs.max(1)
                    val_total += labels.size(0)
                    val_correct += predicted.eq(labels).sum().item()

            val_loss /= val_total
            val_acc = val_correct / val_total

            log = {
                "epoch": epoch + 1,
                "train_loss": round(train_loss, 4),
                "train_acc": round(train_acc, 4),
                "val_loss": round(val_loss, 4),
                "val_acc": round(val_acc, 4)
            }
            # === ä¿å­˜æ—¥å¿—åˆ°å†…å­˜ ===
            self.logs.append(log)
            # === å®æ—¶æ‰“å°ä¸æ¨é€ ===
            print(f"[Epoch {epoch+1}/{num_epochs}] "
                  f"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, "
                  f"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, ")

            if self.progress_callback:
                self.progress_callback(log)

        # === ä¿å­˜æ¨¡å‹ ===
        save_path = os.path.join(save_dir, f"{model_name}.pth")
        torch.save(model.state_dict(), save_path)
        print(f"âœ… è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ°: {os.path.abspath(save_path)}")

        # === ä¿å­˜è®­ç»ƒæ—¥å¿— ===
        log_path = os.path.join(save_dir, f"{model_name}_log.json")
        with open(log_path, "w", encoding="utf-8") as f:
            json.dump(self.logs, f, indent=4, ensure_ascii=False)
        print(f"ğŸ“˜ è®­ç»ƒæ—¥å¿—å·²ä¿å­˜åˆ°: {os.path.abspath(log_path)}")


        return {
            "model_path": save_path,
            "final_train_acc": train_acc,
            "final_val_acc": val_acc
        }
